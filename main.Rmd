---
output:
  pdf_document: default
  html_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(readr)
library(knitr)
library(tidyverse)
library(janitor)
library(visdat)
library(gtsummary)
```

## Introduction

Tennis is one of the most popular sports around the world. The game is very dynamic and has a lot of moving parts: serving, baseline play, and net play. Each match consists of many points, and thus a lot of data can be collected about each player's performance over the course of an entire match. The goal of this analysis is to understand which match and/or player statistics have the strongest associations with winning a match and to quantify those associations.   

The dataset we are analyzing contains match statistics from 943 men's and women's matches which occurred in one of four grand slam tournaments in 2013: the Australian Open, the French Open, Wimbledon, and the US Open. Each observation is an individual match. The response variable is a binary indicator: a value of 1 indicates that player 1 won the match, and a value of 0 indicates that player 1 lost the match (the player numbers are arbitrarily assigned and correspond to which player name is listed first for each observation). The match statistics recorded for each observation are First Serve Percentage, First Serves Won, Second Serve Percentage, Second Serves Won, Aces, Double Faults, Winners, Unforced Errors, Break Points Created, Break Points Won, Net Points Attempted, Net Points Won, Total Points Won, Results for each set, and Final Number of Games Won (recorded for each player). The Australian Open and the US Open are both played on hard court, the French Open is played on clay, and Wimbledon is played on grass.

Our primary research question for this analysis is: Which tennis match statistics are most strongly associated with winning, and does that vary by gender and/or court surface?


## Methodology

### Data

```{r}
aus_men <- read_csv("AusOpen-men-2013.csv")
aus_women <- read_csv("AusOpen-women-2013.csv")

french_men <- read_csv("FrenchOpen-men-2013.csv")
french_women <- read_csv("FrenchOpen-women-2013.csv")

us_men <- read_csv("USOpen-men-2013.csv")
us_women <- read_csv("USOpen-women-2013.csv")

wimbledon_men <- read_csv("Wimbledon-men-2013.csv")
wimbledon_women <- read_csv("Wimbledon-women-2013.csv")
```


After examining the data, I first selected only for relevant match statistics: player names were removed because I am not considering any background information about specific players in my analysis, and the results at the end of each set and the total games won were removed because I am only interested in purely how players' performance during the points is associated with the final winner.  

I also noticed that virtually every observation from the US Open had some missing data. Thus, I completely removed data from the US Open from my analysis and only analyzed data from the other three grand slam tournaments (one of each surface). In the remaining data, 74 out of 741 observations had some missingness with no clear pattern. Because this was a relatively small number of observations with no clear pattern of missingness, I dropped the observations with missing data from my analysis. However, it is worth noting I have not verified the assumption that the missing data is missing completely at random. 

```{r}

aus_women_stats <- aus_women %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "women", tournament = "australian")

aus_men_stats <- aus_men %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "men", tournament = "australian")

french_women_stats <- french_women %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "women", tournament = "french")

french_men_stats <- french_men %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "men", tournament = "french")

us_women_stats <- us_women %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2)

us_men_stats <- us_men %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2)

wimbledon_women_stats <- wimbledon_women %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "women", tournament = "wimbledon")

wimbledon_men_stats <- wimbledon_men %>%
  select(Result,FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2) %>%
  mutate(gender = "men", tournament = "wimbledon")

aus_open <- rbind(aus_women_stats, aus_men_stats)
french_open <- rbind(french_women_stats, french_men_stats)
wimbledon <- rbind(wimbledon_women_stats, wimbledon_men_stats)
merge1 <- rbind(aus_open, french_open)
data <- rbind(merge1, wimbledon)

data_final <- na.omit(data)
```

To visually investigate the associations between match statistics and match winners, I created bar plots comparing player 1 statistics when player 1 won and when player 1 lost. 

```{r}
FSP_plot <- ggplot(data_final, aes(factor(Result), FSP.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 First Serve Percentage', x = "Winner", y = "First Serve Percentage")
```

```{r}
FSW_plot <- ggplot(data_final, aes(factor(Result), FSW.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 First Serves Won', x = "Winner", y = "First Serves Won")
```


```{r}
SSW_plot <- ggplot(data_final, aes(factor(Result), SSW.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Second Serves Won', x = "Winner", y = "Second Serves Won")
```

```{r}
ACE_plot <- ggplot(data_final, aes(factor(Result), ACE.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Aces', x = "Winner", y = "Number of Aces")
```

```{r}
WNR_plot <- ggplot(data_final, aes(factor(Result), WNR.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Winners', x = "Winner", y = "Number of Winners")
```

```{r}
UFE_plot <- ggplot(data_final, aes(factor(Result), UFE.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Unforced Errors', x = "Winner", y = "Unforced Errors")
```

```{r}
BPC_plot <- ggplot(data_final, aes(factor(Result), BPC.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Break Points Created', x = "Winner", y = "Break Points Created")
```

```{r}
BPW_plot <- ggplot(data_final, aes(factor(Result), BPW.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Break Points Won', x = "Winner", y = "Break Points Won")
```

```{r}
library(ggpubr)
theme_set(theme_pubr())

boxplots <- ggarrange(FSP_plot, FSW_plot, SSW_plot, ACE_plot, WNR_plot, UFE_plot, BPC_plot, BPW_plot,
                      ncol = 2, nrow = 2)

boxplots
```

See Appendix A for boxplots of the remaining predictor variables, which I chose not to include because they did not show any differences as large as those shown above.

### Modeling

With a set of predictors and a binary response variable, I started my analysis with logistic regression modeling.

Evaluating the correlation of all the predictor variables showed that Second Serve Percentage is perfectly negatively correlated with First Serve Percentage for both players (as shown in Appendix B). Therefore, I removed Second Serve Percentage entirely from my models.

I began with building a logistic regression model from the full dataset. Then, I created one logistic regression model only with data from matches between women, and another logistic regression model only with data from matches between men. Finally, I made three separate logistic regression models for each of the three different tournaments (Australian Open, French Open, and Wimbledon). 

I followed the same framework of analysis to build boosted classification trees. As a result, I have built separate boosted trees for the full dataset, the data from matches between women, the data from matches between men, the data from Australian Open matches, the data from French Open matches, and the data from Wimbledon matches,

By building two different types of models on many different subsets of data, I hope to illuminate some insight on which match statistics are most strongly associated with winning and how that might change for different genders and different court surfaces.


## Results

### Overall Logistic Regression Model

```{r}
linearmodel_overall <- lm(Result ~ . - gender - tournament - Result - SSP.1 - SSP.2, data_final, family = "binomial")
data.frame(summary(linearmodel_overall)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...t..`,2) ==0, "<0.01", round(`Pr...t..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="Overall Logistic Regression Model")
```

The overall logistic regression model shows that Break Points Created has the strongest association with winning, followed by First Serves Won and Break Points Won.  

Specifically, every one-unit increase in number of break points created by player 1 is associated with an expected increase of approximately 0.032 in the log-odds of player 1 winning the match, holding all other variables in the model constant. Similarly, every one-unit increase in number of break points created by player 2 is associated with an expected decrease of approximately 0.032 in the log-odds of player 1 winning the match, holding all other variables in the model constant. 

Every one-unit increase in number of first serves won by player 1 is associated with an expected increase of approximately 0.021 in the log-odds of player 1 winning the match, holding all other variables in the model constant. Similarly, every one-unit increase in number of first serves won by player 2 is associated with an expected decrease of approximately 0.021 in the log-odds of player 1 winning the match, holding all other variables in the model constant.

Every one-unit increase in number of break points won by player 1 is associated with an expected increase of approximately 0.024 in the log-odds of player 1 winning the match, holding all other variables in the model constant. Every one-unit increase in number of break points won by player 2 is associated with an expected decrease of approximately 0.013 in the log-odds of player 1 winning the match, holding all other variables in the model constant. 

### Logistic Regression Model for Women

```{r}
data_women <- data_final %>%
  filter(gender == "women")

linearmodel_women <- glm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2  + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data_women, family = "binomial")

data.frame(summary(linearmodel_women)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...z..`,2) ==0, "<0.01", round(`Pr...z..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="Women Logistic Regression Model")
```

The logistic regression model for women shows that Break Points Created has the strongest association with winning, followed by First Serves Won and Break Points Won. These factors are the same factors as the overall logistic regression model, but the magnitude of the coefficients is much larger. This difference in magnitude between the coefficients of the two different models is likely because the model for only women uses much less data as it is only a subset of the original data. Note that majority of the coefficients in this model are statistically insignificant.  

### Logistic Regression Model for Men

```{r}
data_men <- data_final %>%
  filter(gender == "men")

linearmodel_men <- glm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2  + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data_women, family = "binomial")

data.frame(summary(linearmodel_men)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...z..`,2) ==0, "<0.01", round(`Pr...z..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="Men Logistic Regression Model")
```

The logistic regression model for men shows that Break Points Created has the strongest association with winning, followed by First Serves Won and Break Points Won. These factors are the same factors as the overall logistic regression model, but the magnitude of the coefficients is much larger. This difference in magnitude between the coefficients of the two different models is likely because the model for only men uses much less data as it is only a subset of the original data. The magnitudes of the coefficients of the logistic model for men are relatively similar to the magnitudes of the coefficients of the logistic model for women. Thus, these models fail to show meaningful differences between men and women in the associations of match statistics and match winners. Note that majority of the coefficients in this model are statistically insignificant. 


### Australian Open

```{r}
linearmodel_aus <- glm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, aus_open, family = "binomial")

data.frame(summary(linearmodel_aus)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...z..`,2) ==0, "<0.01", round(`Pr...z..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="Australian Open Logistic Regression Model")

```

The logistic regression model for the Australian Open shows that Break Points Created has the strongest association with winning, followed by Number of Double Faults and Second Serves Won. While the first strongest factor is the same as the overall logistic regression model, the following two are not. In addition, the magnitude of the coefficients is much larger. This difference in magnitude between the coefficients of the two different models is likely because the model for only the Australian Open uses much less data than any of the above models as it is only a subset of the original data. Many of the coefficients go against intuition (for example, the model shows that player 1 winning net points is associated with a decrease in the log-odds of player 1 winning on average and holding all other variables in the model constant). Note that majority of the coefficients in this model are statistically insignificant. Considering all the above, the very small sample size for only Australian Open data severely reduces the accuracy of interpretations based on this logistic regression model. 

### French Open

```{r}
linearmodel_french <- glm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, french_open, family = "binomial")

data.frame(summary(linearmodel_french)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...z..`,2) ==0, "<0.01", round(`Pr...z..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="French Open Logistic Regression Model")
```

The logistic regression model for the French Open shows that Break Points Created has the strongest association with winning, followed by Number of Double Faults. These factors are the same as the factors most strongly associated with winning in the Australian Open model. However, like the Australian Open model, the magnitudes of the coefficients of this model are much larger than those of the overall logistical model. This difference is likely because the model for only the French Open uses much less data than any of the above models as it is only a subset of the original data. The rest of the coefficients go against intuition (for example, the model shows that player 1 winning net points is associated with a decrease in the log-odds of player 1 winning on average and holding all other variables in the model constant). Note that all of the coefficients in this model are statistically insignificant. Considering all the above, the very small sample size for only French Open data severely reduces the accuracy of interpretations based on this logistic regression model. 


### Wimbledon

```{r}
linearmodel_wimbledon <- glm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, wimbledon, family = "binomial")

data.frame(summary(linearmodel_wimbledon)$coef) %>%
  mutate(`Coefficient` = Estimate, `P-Value` = ifelse(round(`Pr...z..`,2) ==0, "<0.01", round(`Pr...z..`,2))) %>%
  dplyr::select(`Coefficient`, `P-Value`) %>% 
  tibble::rownames_to_column(var= "Variable") %>% 
  mutate(Variable = case_when(Variable == "FSP.1" ~ "First Serve Percentage (Player 1)",
                              Variable == "FSP.2" ~ "First Serve Percentage (Player 2)",
                              Variable == "FSW.1" ~ "First Serves Won (Player 1)",
                              Variable == "FSW.2" ~ "First Serves Won (Player 2)",
                              Variable == "SSW.1" ~ "Second Serves Won (Player 1)",
                              Variable == "SSW.2" ~ "Second Serves Won (Player 2)",
                              Variable == "ACE.1" ~ "Number of Aces (Player 1)",
                              Variable == "ACE.2" ~ "Number of Aces (Player 2)",
                              Variable == "DBF.1" ~ "Number of Double Faults (Player 1)",
                              Variable == "DBF.2" ~ "Number of Double Faults (Player 2)",
                              Variable == "WNR.1" ~ "Number of Winners (Player 1)",
                              Variable == "WNR.2" ~ "Number of Winners (Player 2)",
                              Variable == "UFE.1" ~ "Number of Unforced Errors (Player 1)",
                              Variable == "UFE.2" ~ "Number of Unforced Errors (Player 2)",
                              Variable == "BPC.1" ~ "Break Points Created (Player 1)",
                              Variable == "BPC.2" ~ "Break Points Created (Player 2)",
                              Variable == "BPW.1" ~ "Break Points Won (Player 1)",
                              Variable == "BPW.2" ~ "Break Points Won (Player 2)",
                              Variable == "NPA.1" ~ "Net Points Attempted (Player 1)",
                              Variable == "NPA.2" ~ "Net Points Attempted (Player 2)",
                              Variable == "NPW.1" ~ "Net Points Won (Player 1)",
                              Variable == "NPW.2" ~ "Net Points Won (Player 2)",
                              Variable == "(Intercept)" ~ "Intercept")) %>% 
  kable(format = "markdown", digits=3, caption="Wimbledon Logistic Regression Model")
```

The logistic regression model for Wimbledon shows that Break Points Won has the strongest association with winning, followed by First Serves Won. These factors are different from the factors most strongly associated with winning in the previous models. However, like the Australian Open and French Open models, the magnitudes of the coefficients of this model are somewhat larger than those of the overall logistical model. This difference is likely because the model for only Wimbledon uses much less data than any of the above models as it is only a subset of the original data. The rest of the coefficients go against intuition (for example, the model shows that player 1 winning net points is associated with a decrease in the log-odds of player 1 winning on average and holding all other variables in the model constant). Note that almost all of the coefficients in this model are statistically insignificant (except Break Points Won). Considering all the above, the very small sample size for only Wimbledon data severely reduces the accuracy of interpretations based on this logistic regression model.


### Classification Tree

```{r}
# Classification Tree with rpart
library(rpart) #for fitting decision trees
library(rpart.plot) #for plotting decision trees

# grow tree
fit <- rpart(Result ~ . - gender - tournament - Result,
   method="class", data= data_final)

printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits

# plot tree
plot(fit, uniform=TRUE,
   main="Classification Tree for Match Winner")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

```

```{r}
best <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]

#produce a pruned tree based on the best cp value
pruned_tree <- prune(fit, cp=best)

#plot the pruned tree
prp(pruned_tree,
    faclen=0, #use full names for factor labels
    extra=1, #display number of obs. for each terminal node
    roundint=F, #don't round to integers in output
    digits=5)
```

```{r}
library(gbm)
set.seed(1)
boost <- gbm(Result ~.-gender - tournament - Result, data = data_final, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost)
```

```{r}
library(gbm)
set.seed(1)
boost_women <- gbm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data = data_women, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost_women)
```

```{r}
library(gbm)
set.seed(1)
boost_men <- gbm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data = data_men, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost_men)
```

```{r}
library(gbm)
set.seed(1)
boost_aus <- gbm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data = aus_open, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost_aus)
```

```{r}
library(gbm)
set.seed(1)
boost_french <- gbm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data = french_open, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost_french)
```


```{r}
library(gbm)
set.seed(1)
boost_wimbledon <- gbm(Result ~ FSP.1 + FSP.2 + FSW.1 + FSW.2 + SSW.1 + SSW.2 + ACE.1 + ACE.2 + DBF.1 + DBF.2 + WNR.1 + WNR.2 + UFE.1 + UFE.2 + BPC.1 + BPC.2 + BPW.1 + BPW.2 + NPA.1 + NPA.2 + NPW.1 + NPW.2, data = wimbledon, 
                    distribution = "multinomial", n.trees = 5000,
                    interaction.depth = 3)
summary(boost_wimbledon)
```


## Discussion

LIMITATIONS
- split by gender AND surface type
- not missing completely at random
- not enough observations
- high correlation between variables
- coefficients in model not statistically significant
- did not account for player demographics, skill level, ranking, etc.
- from 2013, could be outdated

## Appendix

### Appendix A

```{r}
DBF_plot <- ggplot(data_final, aes(factor(Result), DBF.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Double Faults', x = "Winner", y = "Double Faults")
DBF_plot
```

```{r}
NPA_plot <- ggplot(data_final, aes(factor(Result), NPA.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Net Points Attempted', x = "Winner", y = "Net Points Attempted")
NPA_plot
```

```{r}
NPW_plot <- ggplot(data_final, aes(factor(Result), NPW.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Net Points Won', x = "Winner", y = "Net Points Won")
NPW_plot
```

```{r}
SSP_plot <- ggplot(data_final, aes(factor(Result), SSP.1)) +
  geom_boxplot() +
  labs(title = 'Winner And Player 1 Second Serve Percentage', x = "Winner", y = "Second Serve Percentage")
SSP_plot
```

### Appendix B

```{r}
dataframe <- data_final %>%
  select(FSP.1,FSP.2,FSW.1,FSW.2,SSP.1,SSP.2,SSW.1,SSW.2,ACE.1,ACE.2,DBF.1,DBF.2,WNR.1,WNR.2,UFE.1,UFE.2,BPC.1,BPC.2,BPW.1,BPW.2,NPA.1,NPA.2,NPW.1,NPW.2)
```

```{r}
library(car)
cor(dataframe)
```